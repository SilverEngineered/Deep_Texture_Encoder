{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Texture Encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Purpose:** \n",
    "The purpose of this texture encoder is to create a many to one distillation of images using neural networks.  There are 2 modes to this. One is a residual network that adds a mask to the original image and calculates loss based on the new image, and the other is a complete reconstruction of the image without a residual component to the network. The goal is to create a mapping between many textures to one common texture to aid a reinforcement learning network in simulation to enable adaptability in transfering learning from one texture to that of another.  All of the input images to this network are images captured from random coorinates on a proceduraly generated maze from the Unity Game Engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup:** \n",
    "A requirement for this program to work is to have many folder in this directory that contains many folders all with the same images, but in different textures, with one folder named \"real\".  The \"real\" folder will be the texture that the other textures will map to.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure arguments for this network:\n",
    "`parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset_dir', dest='dataset_dir', default='data', help='path of the directories containing textured images')\n",
    "parser.add_argument('--generalized_data', dest='generalized_data', default='real', help='path within dataset_dir that contains the images to be generalized to')\n",
    "parser.add_argument('--test_dir_x', dest='test_dir_x', default='cropped_10k_lsun_test', help='path of the test dataset')\n",
    "parser.add_argument('--ck_path', dest='ck_path', default='checkpoints', help='checkpoint path')\n",
    "parser.add_argument('--epoch', dest='epoch', type=int, default=200000, help='# of epoch')\n",
    "parser.add_argument('--learning_rate', dest='lr', type=float, default=.0001,help='learning rate')\n",
    "parser.add_argument('--image_shape', dest='image_shape',default=[256,256,3], help='shape of each image')\n",
    "parser.add_argument('--vector_dims', dest='vector_dims',default=1000, help='Dimensionality of the encoded vector')\n",
    "parser.add_argument('--small_network', dest='small_network',default=False, help='use simple network')\n",
    "parser.add_argument('--residual', dest='residual',default=False, help='use a residual network')\n",
    "parser.add_argument('--load', dest='load',default=True, help='Load weights')\n",
    "args = parser.parse_args()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate and train Phi (texture transfer function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    with tf.Session(config=tfconfig) as sess:\n",
    "        model = phi(sess, args)\n",
    "        model.train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Initialize values for Phi with specified Arguments\n",
    "    \n",
    "    def __init__(self, sess, args):\n",
    "        self.sess = sess\n",
    "        self.dataset_dir = args.dataset_dir\n",
    "        self.generalized_data = args.generalized_data\n",
    "        self.lr = args.lr\n",
    "        self.epoch = args.epoch\n",
    "        self.image_shape = args.image_shape\n",
    "        self.vector_dims = args.vector_dims\n",
    "        self.small_network = args.small_network\n",
    "        self.residual = args.residual\n",
    "        self.load_checkpoint=args.load\n",
    "        self.num_textures=8\n",
    "        if not self.load_checkpoint:\n",
    "            self.texture_data = nnUtils.import_images_ignore(args.dataset_dir,args.generalized_data,size=[4,args.image_shape[0],args.image_shape[1],args.image_shape[2]])\n",
    "            self.real_data = nnUtils.import_images(os.path.join(args.dataset_dir,args.generalized_data))\n",
    "            print(\"Imported Data!\")\n",
    "            self.num_textures = self.texture_data.shape[0]\n",
    "\n",
    "        if not self.small_network:\n",
    "            self.encoder = encoder\n",
    "            self.decoder = decoder\n",
    "        else:\n",
    "            self.encoder = small_network\n",
    "        self.build()\n",
    "        if self.load_checkpoint:\n",
    "            self.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build(self) is called within the initialization of Phi and assembles the architecture for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(self):\n",
    "        self.x = tf.placeholder(tf.float32, [None, self.image_shape[0], self.image_shape[1], 3])\n",
    "        self.y = tf.placeholder(tf.float32, [self.image_shape[0], self.image_shape[1], 3])\n",
    "        if not self.small_network:\n",
    "            self.encoder_net = self.encoder(self.x,self.vector_dims, reuse=False)\n",
    "            self.decoder_net = self.decoder(self.encoder_net,self.image_shape,reuse=False)\n",
    "        else:\n",
    "            self.encoder_net = self.encoder(self.x,reuse=False)\n",
    "        self.vars=tf.trainable_variables()\n",
    "        if not self.small_network:\n",
    "            self.loss=loss(self.decoder_net,self.y,self.x,self.num_textures,self.residual)\n",
    "        else:\n",
    "            self.loss=loss(self.encoder_net,self.y,self.x,self.num_textures,self.residual)\n",
    "            \n",
    "        self.optim = tf.train.AdamOptimizer(self.lr).minimize(self.loss, var_list=self.vars)\n",
    "        \n",
    "        #Saver for creating and loading checkpoints\n",
    "        self.saver = tf.train.Saver()\n",
    "        print(\"Built!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate phi object and train \n",
    "`with tf.Session(config=tfconfig) as sess:\n",
    "        model = phi(sess, args)\n",
    "        model.train(args)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set arguments in phi object\n",
    "`def __init__(self, sess, args):\n",
    "        self.sess = sess\n",
    "        self.dataset_dir_x = args.dataset_dir_x\n",
    "        self.test_dir_x = args.test_dir_x\n",
    "        self.fig_output=args.fig_output\n",
    "        self.epoch = args.epoch\n",
    "        self.lr = args.lr\n",
    "        self.dataset_dir_x = args.dataset_dir_x\n",
    "        self.beta1 = args.beta1\n",
    "        self.image_shape = args.image_shape\n",
    "        self.batch_size = args.bs\n",
    "        self.phi_network = phi_network_residual\n",
    "        self.input= nnUtils.import_images(self.dataset_dir_x)\n",
    "        self.input_indecies=np.load(args.indecies_file)\n",
    "        self.num_bins=args.num_bins\n",
    "        self.alpha=args.alpha\n",
    "        self.vector_dims=args.vector_dims\n",
    "        self.graph = args.graph\n",
    "        self.graph_freq = args.graph_freq\n",
    "        self.graph_amount=args.graph_amount\n",
    "        self.plot_loss=args.plot_loss\n",
    "        self.solid_shapes = args.solid_shapes\n",
    "        self.plot3d=args.plot3d\n",
    "        self.build()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### encoder(x,vector_dims) \n",
    "\n",
    "###### Purpose: \n",
    "Creates an encoder network to create an n-dimensional embedding to represent a feature space of the images\n",
    "\n",
    "###### args: \n",
    "\n",
    "x - the input image to the encoder network\n",
    "\n",
    "vector_dims - the dimensionality of the output feature space\n",
    "\n",
    "name - name of the network\n",
    "\n",
    "activation - the activation function of the \n",
    "###### Returns:\n",
    "A residual layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x,vector_dims,reuse=False, name=\"encoder\", activation=tf.nn.relu,num_filters=32, kernel_size=[5,5],stride=[1,1]):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        x = residual_block(x,num_filters,kernel_size)\n",
    "        x = residual_block(x,num_filters,kernel_size)\n",
    "        x = residual_block(x,num_filters,kernel_size)\n",
    "        x = residual_block(x,num_filters,kernel_size)\n",
    "        x = tf.contrib.slim.conv2d_transpose(x, 1, kernel_size, stride, padding='SAME')\n",
    "        x = tf.layers.batch_normalization(x)\n",
    "        x = tf.contrib.layers.flatten(x)\n",
    "        x = tf.layers.dense(x,vector_dims, activation=activation)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### decoder(x,image_shape)\n",
    "\n",
    "###### Purpose: \n",
    "Decode the n-dimensional vector created by the encoder network into an image\n",
    "\n",
    "###### args: \n",
    "\n",
    "x - the input layer\n",
    "\n",
    "image_shape - the shape of the image to be created\n",
    "\n",
    "name - name of the layer\n",
    "###### Returns:\n",
    "An image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(x,image_shape,reuse=False, name=\"decoder\", activation=tf.nn.relu,num_filters=128,stride=[2,2],kernel=[4,4]):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        x = tf.expand_dims(tf.expand_dims(x, 1), 1)\n",
    "        print(x.shape)\n",
    "        x = tf.layers.dense(x,int(image_shape[0]*image_shape[1]*image_shape[2]/16))\n",
    "        print(x.shape)\n",
    "        x = tf.reshape(x,[-1,int(image_shape[0]/4),int(image_shape[1]/4),image_shape[2]])\n",
    "        print(x.shape)\n",
    "        x = tf.layers.conv2d_transpose(x,num_filters,kernel,stride, padding=\"SAME\")\n",
    "        print(x.shape)\n",
    "        x = tf.layers.conv2d_transpose(x,int(num_filters/2),kernel,stride, padding=\"SAME\")\n",
    "        print(x.shape)\n",
    "        x = tf.layers.conv2d_transpose(x,int(num_filters/4),kernel,stride, padding=\"SAME\")\n",
    "        print(x.shape)\n",
    "        x = tf.layers.conv2d_transpose(x,int(num_filters/8),kernel,stride, padding=\"SAME\")\n",
    "        print(x.shape)\n",
    "        x = tf.layers.conv2d_transpose(x,3,kernel,stride, padding=\"SAME\")\n",
    "        print(x.shape)\n",
    "        x = tf.layers.conv2d(x,3,kernel,stride, padding=\"SAME\")\n",
    "        print(x.shape)\n",
    "        x = tf.layers.conv2d(x,3,kernel,stride, padding=\"SAME\")\n",
    "        print(x.shape)\n",
    "        x = tf.layers.conv2d(x,3,kernel,stride, padding=\"SAME\")\n",
    "        print(x.shape)\n",
    "        #exit()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self,args):\n",
    "        '''\n",
    "        Trains the triplet network by having it learn an embedding into args.vector_dims dimensional space.\n",
    "        :param args: StringArray, Arguments passed in from argument parser\n",
    "        '''\n",
    "\n",
    "        loss_scalar = tf.summary.scalar(\"Loss\", self.loss)\n",
    "        init=tf.global_variables_initializer()\n",
    "        train_writer = tf.summary.FileWriter( './logs/train ', self.sess.graph)\n",
    "        dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "        checkpoint = os.path.join(dir_path,\"checkpoints/\",)\n",
    "\n",
    "        self.sess.run(init)\n",
    "        iter=0\n",
    "        print(\"Training initialized\")\n",
    "        all_loss=[]\n",
    "        for i in range(self.epoch):\n",
    "            index_transform = random.randint(0, self.real_data.shape[0]-1)\n",
    "            texture_batch=np.zeros([self.num_textures,self.image_shape[0],self.image_shape[1],self.image_shape[2]])\n",
    "            for x in range(self.num_textures):\n",
    "                texture_batch[x]=self.texture_data[x][index_transform]\n",
    "            real_batch=self.real_data[index_transform]\n",
    "            if not self.small_network:\n",
    "                loss_data, _, generated, _ = self.sess.run([self.loss,self.optim,self.decoder_net, self.encoder_net],feed_dict={self.x: texture_batch, self.y: real_batch})\n",
    "            else:\n",
    "                loss_data, _, generated = self.sess.run([self.loss,self.optim,self.encoder_net],feed_dict={self.x: texture_batch, self.y: real_batch})\n",
    "            #print(loss_data)\n",
    "            img_texture = 5\n",
    "            img_texture_2 = 6\n",
    "            img_texture_3 = 7\n",
    "            img_mod = 100\n",
    "            img_path = './results/'\n",
    "            if i%img_mod==0:\n",
    "                if self.residual:\n",
    "                    #Save generated images to path\n",
    "                    generated_image = util.scale_data(generated[img_texture] + texture_batch[img_texture],[0,255])\n",
    "                    cv2.imwrite(img_path + 'generated_images/' + str(int(i/img_mod)) + \".jpg\", generated_image)\n",
    "                    generated_image = util.scale_data(generated[img_texture_2] + texture_batch[img_texture_2],[0,255])\n",
    "                    cv2.imwrite(img_path + 'generated_images_2/' + str(int(i/img_mod)) + \".jpg\", generated_image)\n",
    "                    generated_image = util.scale_data(generated[img_texture_3] + texture_batch[img_texture_3],[0,255])\n",
    "                    cv2.imwrite(img_path + 'generated_images_3/' + str(int(i/img_mod)) + \".jpg\", generated_image)\n",
    "                    mask = util.scale_data(generated[img_texture],[0,255])\n",
    "                    cv2.imwrite(img_path + 'masks/' + str(int(i/img_mod)) + \".jpg\", mask)\n",
    "                    mask = util.scale_data(generated[img_texture_2],[0,255])\n",
    "                    cv2.imwrite(img_path + 'masks_2/' + str(int(i/img_mod)) + \".jpg\", mask)\n",
    "                    mask = util.scale_data(generated[img_texture_3],[0,255])\n",
    "                    cv2.imwrite(img_path + 'masks_3/' + str(int(i/img_mod)) + \".jpg\", mask)\n",
    "                else:\n",
    "                    img = util.scale_data(generated[img_texture],[0,255])\n",
    "                    cv2.imwrite(img_path + 'generated_images/' + str(int(i/img_mod)) + \".jpg\", img)\n",
    "                    img = util.scale_data(generated[img_texture_2],[0,255])\n",
    "                    cv2.imwrite(img_path + 'generated_images_2/' + str(int(i/img_mod)) + \".jpg\", img)\n",
    "                    img = util.scale_data(generated[img_texture_3],[0,255])\n",
    "                    cv2.imwrite(img_path + 'generated_images_3/' + str(int(i/img_mod)) + \".jpg\", img)\n",
    "                target_image = util.scale_data(real_batch,[0,255])\n",
    "                cv2.imwrite(img_path + 'target/' + str(int(i/img_mod)) + \".jpg\", target_image)\n",
    "                original_image = util.scale_data(texture_batch[img_texture],[0,255])\n",
    "                cv2.imwrite(img_path + 'original/' + str(int(i/img_mod)) + \".jpg\", original_image)\n",
    "                original_image = util.scale_data(texture_batch[img_texture_2],[0,255])\n",
    "                cv2.imwrite(img_path + 'original_2/' + str(int(i/img_mod)) + \".jpg\", original_image)\n",
    "                original_image = util.scale_data(texture_batch[img_texture_3],[0,255])\n",
    "                cv2.imwrite(img_path + 'original_3/' + str(int(i/img_mod)) + \".jpg\", original_image)\n",
    "                self.saver.save(self.sess, checkpoint, global_step=img_mod)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint to resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load(self):\n",
    "        dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "        checkpoint = os.path.join(dir_path,\"checkpoints/\",)\n",
    "        self.saver.restore(self.sess, tf.train.latest_checkpoint(checkpoint))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
